{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uszipcode in d:\\anaconda\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: sqlalchemy in d:\\anaconda\\lib\\site-packages (from uszipcode) (1.3.13)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from uszipcode) (2.22.0)\n",
      "Requirement already satisfied: attrs in d:\\anaconda\\lib\\site-packages (from uszipcode) (19.3.0)\n",
      "Requirement already satisfied: pathlib-mate in d:\\anaconda\\lib\\site-packages (from uszipcode) (1.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->uszipcode) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->uszipcode) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests->uszipcode) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->uszipcode) (2.8)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from pathlib-mate->uszipcode) (1.14.0)\n",
      "Requirement already satisfied: autopep8 in d:\\anaconda\\lib\\site-packages (from pathlib-mate->uszipcode) (1.4.4)\n",
      "Requirement already satisfied: pycodestyle>=2.4.0 in d:\\anaconda\\lib\\site-packages (from autopep8->pathlib-mate->uszipcode) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install uszipcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uszipcode import Zipcode, SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.redfin.com/zipcode/10026\n"
     ]
    }
   ],
   "source": [
    "zipcode=\"10026\"\n",
    "url=\"https://www.redfin.com/\"+ \"zipcode/\" + zipcode\n",
    "print(url)\n",
    "\n",
    "#automatically map the zipcode to cityname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New-York\n"
     ]
    }
   ],
   "source": [
    "search = SearchEngine()\n",
    "cityCode = search.by_zipcode(zipcode)\n",
    "cityName = cityCode.major_city\n",
    "city = cityName.replace(\" \", \"-\")\n",
    "print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get basic url info\n",
    "def getHTMLText(url):\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) \\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102. Safari/537.36'}\n",
    "        r = requests.get(url,headers = headers, timeout =30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return\"Wrong page\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.redfin.com/zipcode/10026/filter/property-type=house+condo,min-price=50k,max-price=15.4M,hoa=400,min-sqft=1.0k\n"
     ]
    }
   ],
   "source": [
    "#Redfin with filters\n",
    "filters = \"/filter/property-type=house+condo,min-price=50k,max-price=15.4M,hoa=400,min-sqft=1.0k\"\n",
    "url_1 = url + filters\n",
    "print(url_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111-W-110th-St-10026/home/45207792\n",
      "145-Central-Park-N-10026/home/173388575\n",
      "145-Central-Park-N-10026/home/173387082\n",
      "\n",
      "310-W-113th-St-10026/home/173112317\n",
      "40-W-116th-St-10026/home/45226808\n",
      "1845-Adam-Clayton-Powell-Junior-Blvd-10026/home/173166247\n",
      "111-W-110th-St-10026/home/45207816\n",
      "237-W-115th-St-10026/home/45228107\n",
      "310-W-113th-St-10026/home/173113136\n",
      "145-Central-Park-N-10026/home/173387081\n",
      "371-W-117th-St-10026/home/45316633\n",
      "2110-Frederick-Douglass-Blvd-10026/home/45333133\n",
      "145-Central-Park-N-10026/home/173201170\n",
      "310-W-113th-St-10026/home/173300514\n",
      "310-W-120th-St-10026/home/173377573\n",
      "1400-5th-Ave-10026/home/45134567\n",
      "145-Central-Park-N-10026/home/173204456\n",
      "County\n",
      "313-W-118th-St-10026/home/173293669\n",
      "145-Central-Park-N-10026/home/173388576\n",
      "2073-Frederick-Douglass-Blvd-10026/home/45125442\n",
      "120-W-118th-St-10026/home/144717386\n"
     ]
    }
   ],
   "source": [
    "#define a function to get house in that area\n",
    "def getHouseList(lst, url):\n",
    "    html = getHTMLText(url_1)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    a = soup.find_all('a')\n",
    "    for i in a:\n",
    "        try:\n",
    "            #find all elements with href\n",
    "            href = i.get('href')\n",
    "            #find all where house in NEW YORK\n",
    "            m = re.search(r'/NY/'+ city, href)\n",
    "            #add them into the list\n",
    "            lst.append(href[m.end()+1:])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "lst = []\n",
    "getHouseList(lst, url_1)\n",
    "\n",
    "#remove duplicate lines in the list\n",
    "lst = list(set(lst))\n",
    "\n",
    "\n",
    "print(*lst, sep =\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
