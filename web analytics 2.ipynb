{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sebas'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page 1\n",
      "Parsing page 1\n",
      "Getting page 2\n",
      "Parsing page 2\n",
      "Getting page 3\n",
      "Parsing page 3\n",
      "Getting page 4\n",
      "Parsing page 4\n",
      "Getting page 5\n",
      "Parsing page 5\n",
      "Getting page 6\n",
      "Parsing page 6\n",
      "Getting page 7\n",
      "Parsing page 7\n",
      "Getting page 8\n",
      "Parsing page 8\n",
      "Getting page 9\n",
      "Parsing page 9\n",
      "Getting page 10\n",
      "Parsing page 10\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "\n",
    "movie   = 'the_dark_knight'\n",
    "name    = 'shu guan' # replace here with your name!\n",
    "pageNum = 10\n",
    "\n",
    "# create the movie url\n",
    "url     = 'https://www.rottentomatoes.com/m/'+movie+'/reviews/'\n",
    "\n",
    "# output file\n",
    "with open('web analytics/'+name + '_' + movie+'.txt','w') as fw:\n",
    "    \n",
    "    # for each page out of the pageNum pages you want to parse\n",
    "    for p in range(1,pageNum+1): \n",
    "        \n",
    "        # tell user which page you're parsing\n",
    "        print ('Getting page',p)\n",
    "        \n",
    "        # initialize html file to None\n",
    "        html=None        \n",
    "        \n",
    "        # set URL to get appropriately\n",
    "        #   if it is the first page\n",
    "        if p==1: \n",
    "            # url for page 1\n",
    "            pageLink=url \n",
    "        #   if it is tnot the first page\n",
    "        else: \n",
    "            # url for other pages\n",
    "            pageLink=url+'?page='+str(p)+'&sort=' # make the page url\n",
    "            \n",
    "        # try to scrape times\n",
    "        for i in range(5): \n",
    "            try:\n",
    "                # get url content\n",
    "                response = requests.get(pageLink,headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36', })\n",
    "                # get the html\n",
    "                html=response.content\n",
    "                # if we successuflly got the file, break the loop\n",
    "                break \n",
    "            # requests.get() threw an exception, i.e., the attempt to get the response failed\n",
    "            except:\n",
    "                print ('failed attempt #',i)\n",
    "                # wait 2 secs before trying again\n",
    "                time.sleep(2)\n",
    "\n",
    "        if not html:\n",
    "            # couldnt get the page, ignore\n",
    "            print('could not get page #', p)\n",
    "            continue \n",
    "        \n",
    "        # if we got the page, parse the html file\n",
    "        # first, turn it into a beautiful soup object\n",
    "        soup = BeautifulSoup(html.decode('ascii', 'ignore'),'lxml')\n",
    "        \n",
    "        # then get all the review divs\n",
    "        reviews=soup.findAll('div', {'class':re.compile('review_table_row')})\n",
    "        \n",
    "        # grab the information for each review\n",
    "        print ('Parsing page',p)\n",
    "        \n",
    "        \n",
    "        for review in reviews:\n",
    "            \n",
    "            # initialize critic, rating, source, text, date\n",
    "            critic,rating,source,text,date='NA','NA','NA','NA','NA'\n",
    "            \n",
    "            # 1. if there is critic name information, get it\n",
    "            criticChunk=review.find('a',{'href':re.compile('/critic/')})\n",
    "            if criticChunk: \n",
    "                critic=criticChunk.text.strip()\n",
    "            \n",
    "            # 2. if there is rating information, get it ;\n",
    "            # The rating should be 'rotten' , 'fresh', or 'NA' if the review doesn't have a rating.\n",
    "            ratingfresh=review.find(\"div\", attrs={\"class\":\"review_icon icon small fresh\"} )\n",
    "            ratingrotten=review.find(\"div\", attrs={\"class\":\"review_icon icon small rotten\"} )\n",
    "            if ratingfresh:\n",
    "                rating='fresh'\n",
    "            if ratingrotten:\n",
    "                rating='rotten'\n",
    "            \n",
    "            \n",
    "            # 3. if there is source information, get it\n",
    "            sourceChunk=review.find(\"em\", attrs={\"class\":\"subtle critic-publication\"})\n",
    "            if sourceChunk:\n",
    "                source=sourceChunk.text.strip()\n",
    "            \n",
    "            \n",
    "            # 4. if there is text information, get it    \n",
    "            \n",
    "            T=review.find(\"div\", attrs={\"class\":\"the_review\"})\n",
    "            if T:\n",
    "                text=T.text.strip()\n",
    "            \n",
    "            # 5. if there is date information, get it    \n",
    "            D=review.find(\"div\", attrs={\"class\":\"review-date subtle small\"})\n",
    "            if D:\n",
    "                date=D.text.strip()\n",
    "            \n",
    "\n",
    "                \n",
    "            \n",
    "            #write everything to file    \t\t\n",
    "            fw.write(critic+'\\t'+rating+'\\t'+source+'\\t'+text+'\\t'+date+'\\n')\n",
    "\n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
