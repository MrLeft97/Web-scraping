{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>building_name</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>building_beds</th>\n",
       "      <th>building_baths</th>\n",
       "      <th>redfin_estimates</th>\n",
       "      <th>building_location</th>\n",
       "      <th>property_type</th>\n",
       "      <th>property_size</th>\n",
       "      <th>walking_score</th>\n",
       "      <th>transit_score</th>\n",
       "      <th>bike_score</th>\n",
       "      <th>building_description</th>\n",
       "      <th>building_website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9420 238th St</td>\n",
       "      <td>570,000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>598,867</td>\n",
       "      <td>Floral Park,NY</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>4,000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>\"Won't Last! This Spacious 4-Bedroom, 2-Bath B...</td>\n",
       "      <td>https://www.redfin.com/NY/Floral-Park/9420-238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>95 Locustwood Blvd</td>\n",
       "      <td>525,000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>559,541</td>\n",
       "      <td>Elmont,NY</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>4,000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>\"Magnificent Expanded Cape That's Much Larger ...</td>\n",
       "      <td>https://www.redfin.com/NY/Elmont/95-Locustwood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>852 Cypress Ave Unit 2F</td>\n",
       "      <td>700,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queens,NY</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.redfin.com/NY/Queens/852-Cypress-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>75-05 Utopia Pkwy</td>\n",
       "      <td>775,000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>803,383</td>\n",
       "      <td>Flushing,NY</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>1,440</td>\n",
       "      <td>90.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>\"Large home conveniently located in the heart ...</td>\n",
       "      <td>https://www.redfin.com/NY/Flushing/75-05-Utopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>146-30 177th St</td>\n",
       "      <td>900,000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>922,498</td>\n",
       "      <td>Jamaica,NY</td>\n",
       "      <td>Multi-Family (2-4 Unit)</td>\n",
       "      <td>4,000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>\"Don't miss this meticulously maintained 3 ove...</td>\n",
       "      <td>https://www.redfin.com/NY/Queens/146-30-177th-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>415 Greenwich St Unit 3D</td>\n",
       "      <td>2,999,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York,NY</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.redfin.com/NY/New-York/415-Greenwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>10 W End Ave Unit 21B</td>\n",
       "      <td>1,985,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York,NY</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.redfin.com/NY/New-York/10-W-End-Av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.redfin.com/NY/New-York/80-Riversid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.redfin.com/NY/New-York/35-Wooster-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.redfin.com/NY/New-York/300-E-33rd-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             building_name sold_price  building_beds  \\\n",
       "0             0             9420 238th St    570,000            4.0   \n",
       "1             1        95 Locustwood Blvd    525,000            3.0   \n",
       "2             2   852 Cypress Ave Unit 2F    700,000            NaN   \n",
       "3             3         75-05 Utopia Pkwy    775,000            3.0   \n",
       "4             4           146-30 177th St    900,000            6.0   \n",
       "..          ...                       ...        ...            ...   \n",
       "331         331  415 Greenwich St Unit 3D  2,999,000            NaN   \n",
       "332         332     10 W End Ave Unit 21B  1,985,000            NaN   \n",
       "333         333                       NaN        NaN            NaN   \n",
       "334         334                       NaN        NaN            NaN   \n",
       "335         335                       NaN        NaN            NaN   \n",
       "\n",
       "     building_baths redfin_estimates building_location  \\\n",
       "0               2.0          598,867    Floral Park,NY   \n",
       "1               2.0          559,541         Elmont,NY   \n",
       "2               NaN              NaN         Queens,NY   \n",
       "3               3.0          803,383       Flushing,NY   \n",
       "4               4.0          922,498        Jamaica,NY   \n",
       "..              ...              ...               ...   \n",
       "331             NaN              NaN       New York,NY   \n",
       "332             NaN              NaN       New York,NY   \n",
       "333             NaN              NaN               NaN   \n",
       "334             NaN              NaN               NaN   \n",
       "335             NaN              NaN               NaN   \n",
       "\n",
       "                 property_type property_size  walking_score  transit_score  \\\n",
       "0    Single Family Residential        4,000            72.0            NaN   \n",
       "1    Single Family Residential        4,000            39.0           55.0   \n",
       "2                  Condo/Co-op           NaN           99.0           98.0   \n",
       "3    Single Family Residential        1,440            90.0           63.0   \n",
       "4      Multi-Family (2-4 Unit)        4,000            64.0           62.0   \n",
       "..                         ...           ...            ...            ...   \n",
       "331                Condo/Co-op           NaN           97.0          100.0   \n",
       "332                Condo/Co-op           NaN           96.0          100.0   \n",
       "333                        NaN           NaN            NaN            NaN   \n",
       "334                        NaN           NaN            NaN            NaN   \n",
       "335                        NaN           NaN            NaN            NaN   \n",
       "\n",
       "     bike_score                               building_description  \\\n",
       "0          59.0  \"Won't Last! This Spacious 4-Bedroom, 2-Bath B...   \n",
       "1          42.0  \"Magnificent Expanded Cape That's Much Larger ...   \n",
       "2          81.0                                                NaN   \n",
       "3          64.0  \"Large home conveniently located in the heart ...   \n",
       "4          50.0  \"Don't miss this meticulously maintained 3 ove...   \n",
       "..          ...                                                ...   \n",
       "331        90.0                                                NaN   \n",
       "332        81.0                                                NaN   \n",
       "333         NaN                                                NaN   \n",
       "334         NaN                                                NaN   \n",
       "335         NaN                                                NaN   \n",
       "\n",
       "                                      building_website  \n",
       "0    https://www.redfin.com/NY/Floral-Park/9420-238...  \n",
       "1    https://www.redfin.com/NY/Elmont/95-Locustwood...  \n",
       "2    https://www.redfin.com/NY/Queens/852-Cypress-A...  \n",
       "3    https://www.redfin.com/NY/Flushing/75-05-Utopi...  \n",
       "4    https://www.redfin.com/NY/Queens/146-30-177th-...  \n",
       "..                                                 ...  \n",
       "331  https://www.redfin.com/NY/New-York/415-Greenwi...  \n",
       "332  https://www.redfin.com/NY/New-York/10-W-End-Av...  \n",
       "333  https://www.redfin.com/NY/New-York/80-Riversid...  \n",
       "334  https://www.redfin.com/NY/New-York/35-Wooster-...  \n",
       "335  https://www.redfin.com/NY/New-York/300-E-33rd-...  \n",
       "\n",
       "[336 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv (r'SoldBuilding.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                             stdin=PIPE)\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b309ebf9d5a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\Users\\\\yugem\\\\webdrivers\\\\chromedriver.exe'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#In this data, we mainly focus on data in New York State\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.redfin.com/state/New-York'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[0;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[1;32m---> 83\u001b[1;33m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[0;32m     84\u001b[0m                 )\n\u001b[0;32m     85\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "import requests # to get the website\n",
    "import time     # to force our code to wait a little before re-trying to grab a webpage\n",
    "import re       # to grab the exact element we need\n",
    "from bs4 import BeautifulSoup # to grab the html elements we need\n",
    "import pandas as pd # to create dataframe\n",
    "from selenium import webdriver #use selenium to avoid websiteâ€™s anti-scraping\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "path = 'C:\\\\Users\\\\yugem\\\\webdrivers\\\\chromedriver.exe'\n",
    "browser = webdriver.Chrome(path)\n",
    "#In this data, we mainly focus on data in New York State\n",
    "browser.get('https://www.redfin.com/state/New-York')\n",
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        browser.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "data = []\n",
    "page_source = browser.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "cities = 'NA'\n",
    "avg_price = 'NA'\n",
    "avg_ppersqr = 'NA'\n",
    "avg_day = 'NA'\n",
    "cities_link = 'NA'\n",
    "if (check_exists_by_xpath('//a[@class=\"ui_button nav next primary \"]')):\n",
    "        browser.find_element_by_xpath('//a[@class=\"ui_button nav next primary \"]').click()\n",
    "        time.sleep(4)\n",
    "table = soup.find('table')\n",
    "tbody = table.find('tbody')\n",
    "trs = tbody.find_all('tr')\n",
    "for tr in trs:\n",
    "    lnk = tr.find_all('a')\n",
    "    lnk = lnk[0]\n",
    "    link = lnk.get('href')\n",
    "    cities_link = \"https://www.redfin.com\" + link\n",
    "    cities = lnk.text.strip()\n",
    "    cities = '\"'+ cities + '\"'\n",
    "    td1 = tr.find_all('td',{'class':'c1'})\n",
    "    td1 = td1[0]\n",
    "    avg_price = td1.text.strip()\n",
    "    avg_price = '\"' + avg_price + '\"'\n",
    "    td2 = tr.find_all('td',{'class':'c2'})\n",
    "    td2 = td2[0]\n",
    "    avg_ppersqr = td2.text.strip()\n",
    "    avg_ppersqr = '\"' + avg_ppersqr + '\"'\n",
    "    td3 = tr.find_all('td',{'class':'c3'})\n",
    "    td3 = td3[0]\n",
    "    avg_day = td3.text.strip()\n",
    "    avg_day = '\"' + avg_day + '\"'\n",
    "    \n",
    "    data.append([cities, avg_price, avg_ppersqr, avg_day, cities_link])  \n",
    "#get each citiesâ€™ average price, average price/ sqr ft., average days on redfin, and link \n",
    "df = pd.DataFrame(data, columns = ['Cities', 'Avg.Price', 'Avg.price/sqr', 'Avg.days', 'link'])\n",
    "#In this dataset, we only focus on NYCâ€™s data\n",
    "building_list = []\n",
    "nyc = data[0][4]\n",
    "webpages = 17\n",
    "start = 1\n",
    "for webpage in range(webpages):\n",
    "    if (check_exists_by_xpath('//a[@class=\"ui_button nav next primary \"]')):\n",
    "        browser.find_element_by_xpath('//a[@class=\"ui_button nav next primary \"]').click()\n",
    "        time.sleep(4)\n",
    "    pattern = '/page-'\n",
    "    webpage = nyc + pattern + str(start)\n",
    "    browser.get(webpage)\n",
    "    page_source1 = browser.page_source\n",
    "    soup1 = BeautifulSoup(page_source1, 'lxml')\n",
    "    start += 1\n",
    "    div = soup1.findAll('div', {'class':re.compile('HomeCardContainer')})\n",
    "    for item in div:\n",
    "        if (check_exists_by_xpath('//a[@class=\"ui_button nav next primary \"]')):\n",
    "            browser.find_element_by_xpath('//a[@class=\"ui_button nav next primary \"]').click()\n",
    "            time.sleep(4)\n",
    "        a = item.find('a')\n",
    "        if a == None:\n",
    "            continue\n",
    "        else:\n",
    "            building_link = a.get('href')\n",
    "            website_pattern = 'https://www.redfin.com'\n",
    "            building_link = website_pattern + building_link\n",
    "            browser.get(building_link)\n",
    "            page_source2 = browser.page_source\n",
    "            soup2 = BeautifulSoup(page_source2, 'lxml')\n",
    "            span_address = soup2.find('span', {'class':re.compile('street-address')})\n",
    "            building_name = span_address.text.strip()\n",
    "            building_name = '\"' + building_name + '\"'\n",
    "            div_price = soup2.find('div', {'class':re.compile('statsValue')})\n",
    "            building_price = div_price.text.strip()\n",
    "            building_price = '\"' + building_price + '\"'\n",
    "            div_beds = soup2.find('div', {'data-rf-test-id':'abp-beds'})\n",
    "            building_beds = div_beds.text.strip()\n",
    "            if building_beds == 'â€”Beds':\n",
    "                building_beds = 'NA'\n",
    "            else:\n",
    "                building_beds = '\"' + building_beds + '\"'\n",
    "            div_baths = soup2.find('div', {'data-rf-test-id':'abp-baths'})\n",
    "            building_baths = div_baths.text.strip()\n",
    "            if building_baths == 'â€”Baths':\n",
    "                building_baths = 'NA'\n",
    "            else:\n",
    "                building_baths = '\"' + building_baths + '\"'\n",
    "            description_p = soup2.find('p', {'class':re.compile('text-base')})\n",
    "            if description_p == None:\n",
    "                building_description = 'NA'\n",
    "            else:\n",
    "                building_description = description_p.text.strip()\n",
    "                building_description = '\"' + building_description + '\"'\n",
    "            span_estimate = soup2.find('span', {'data-rf-test-id': 'avmLdpPrice'})\n",
    "            if span_estimate == None:\n",
    "                redfin_estimates = 'NA'\n",
    "            else:\n",
    "                subspan_estimate = span_estimate.find('span', {'class':re.compile('value')})\n",
    "                redfin_estimates = subspan_estimate.text.strip()\n",
    "                redfin_estimates = '\"' + redfin_estimates + '\"'\n",
    "            span_location = soup2.find('span', {'class':re.compile('locality')})\n",
    "            span_region = soup2.find('span', {'class':re.compile('region')})\n",
    "            building_location = span_location.text.strip()\n",
    "            building_region = span_region.text.strip()\n",
    "            building_location = '\"' + building_location + building_region + '\"'\n",
    "            div_type = soup2.findAll('div', {'class':re.compile('table-value')})\n",
    "            if len(div_type) == 0:\n",
    "                property_type = 'NA'\n",
    "                property_size = 'NA'\n",
    "                property_story = 'NA'\n",
    "            else:\n",
    "                property_type = div_type[7].text.strip()\n",
    "                if property_type == 'â€”':\n",
    "                    property_type = 'NA'\n",
    "                else:\n",
    "                    property_type = '\"' + property_type + '\"'\n",
    "                property_size = div_type[4].text.strip()\n",
    "                if property_size == 'â€”':\n",
    "                    property_size = 'NA'\n",
    "                else:\n",
    "                    property_size = '\"' + property_size + '\"'\n",
    "                property_story = div_type[5].text.strip()\n",
    "                if property_story == 'â€”':\n",
    "                    property_size = 'NA'\n",
    "                else:\n",
    "                    property_story = '\"' + property_story + '\"'\n",
    "            walking_div = soup2.find('div', {'class':re.compile('transport-icon-and-percentage walkscore')})\n",
    "            if walking_div == None:\n",
    "                walking_score = 'NA'\n",
    "            else:\n",
    "                walking_span = walking_div.find('span', {'class':re.compile('value')})\n",
    "                walking_score = walking_span.text.strip()\n",
    "                walking_score = '\"' + walking_score + '\"'\n",
    "            transit_div = soup2.find('div', {'class':re.compile('transport-icon-and-percentage transitscore')})\n",
    "            if transit_div == None:\n",
    "                transit_score = 'NA'\n",
    "            else:\n",
    "                transit_span = transit_div.find('span', {'class':re.compile('value')})\n",
    "                transit_score = transit_span.text.strip()\n",
    "                transit_score = '\"' + transit_score + '\"'\n",
    "            bike_div = soup2.find('div', {'class':re.compile('transport-icon-and-percentage bikescore')})\n",
    "            if bike_div == None:\n",
    "                bike_score = 'NA'\n",
    "            else:\n",
    "                bike_span = bike_div.find('span', {'class':re.compile('value')})\n",
    "                bike_score = bike_span.text.strip()\n",
    "                bike_score = '\"' + bike_score + '\"'\n",
    "            \n",
    "            building_list.append([\n",
    "                building_name, building_price, building_beds, \n",
    "                building_baths, redfin_estimates, building_location, \n",
    "                property_type, property_size, property_story, \n",
    "                walking_score, transit_score, bike_score, building_description, building_link])\n",
    "#create dataframe for building_list of active listing buildingâ€™s information\n",
    "df1 = pd.DataFrame(building_list, columns = ['building_name', 'building_price', 'building_beds', \n",
    "                'building_baths', 'redfin_estimates', 'building_location', \n",
    "                'property_type', 'property_size', 'property_story', 'walking_score', 'transit_score',\n",
    "                                             'bike_score', 'building_description', 'building_website'])\n",
    "\n",
    "df1.head(10)\n",
    "sold_list = []\n",
    "webpages = 17\n",
    "filter_pattern = '/filter/include=sold-3mo'\n",
    "start = 1\n",
    "for webpage in range(webpages):\n",
    "    if (check_exists_by_xpath('//a[@class=\"ui_button nav next primary \"]')):\n",
    "        browser.find_element_by_xpath('//a[@class=\"ui_button nav next primary \"]').click()\n",
    "        time.sleep(4)\n",
    "    pattern = '/page-'\n",
    "    webpage1 = nyc + filter_pattern + pattern + str(start)\n",
    "    browser.get(webpage1)\n",
    "    page_source3 = browser.page_source\n",
    "    soup3 = BeautifulSoup(page_source3, 'lxml')\n",
    "    start += 1\n",
    "    divs = soup3.findAll('div', {'class':re.compile('HomeCardContainer')})\n",
    "    for item in divs:\n",
    "        if (check_exists_by_xpath('//a[@class=\"ui_button nav next primary \"]')):\n",
    "            browser.find_element_by_xpath('//a[@class=\"ui_button nav next primary \"]').click()\n",
    "            time.sleep(4) \n",
    "        a = item.find('a')\n",
    "        if a == None:\n",
    "            continue\n",
    "        else:\n",
    "            sold_building_link = a.get('href')\n",
    "            website_pattern = 'https://www.redfin.com'\n",
    "            sold_building_link = website_pattern + sold_building_link\n",
    "            browser.get(sold_building_link)\n",
    "            page_source4 = browser.page_source\n",
    "            soup4 = BeautifulSoup(page_source4, 'lxml')\n",
    "            span_address = soup4.find('span', {'class':re.compile('street-address')})\n",
    "            if span_address == None:\n",
    "                building_name = 'NA'\n",
    "            else:\n",
    "                building_name = span_address.text.strip()\n",
    "                building_name = '\"' + building_name + '\"'\n",
    "            div_price = soup4.find('div', {'data-rf-test-id':'abp-price'})\n",
    "            if div_price == None:\n",
    "                sold_price = 'NA'\n",
    "            else:\n",
    "                subdiv_price = div_price.find('div')\n",
    "                sold_price = subdiv_price.text.strip()\n",
    "                sold_price = '\"' + sold_price + '\"'\n",
    "            redfin_div = soup4.find('div', {'data-rf-test-id':'avm-price'})\n",
    "            if redfin_div == None:\n",
    "                redfin_estimates = 'NA'\n",
    "            else:\n",
    "                subredfin_div = redfin_div.find('div')\n",
    "                redfin_estimates = subredfin_div.text.strip()\n",
    "                redfin_estimates = '\"' + redfin_estimates + '\"'\n",
    "            listed_div = soup4.find('div', {'class':re.compile('price-col number')})\n",
    "            if listed_div == None:\n",
    "                listed_price = 'NA'\n",
    "            else:\n",
    "                listed_price = listed_div.text.strip()\n",
    "                listed_price = '\"' + listed_price + '\"'\n",
    "            div_beds = soup4.find('div', {'data-rf-test-id':'abp-beds'})\n",
    "            if div_beds == None:\n",
    "                building_beds = 'NA'\n",
    "            else:\n",
    "                building_beds = div_beds.text.strip()\n",
    "            if building_beds == 'â€”Beds':\n",
    "                building_beds = 'NA'\n",
    "            else:\n",
    "                building_beds = '\"' + building_beds + '\"'\n",
    "            div_baths = soup4.find('div', {'data-rf-test-id':'abp-baths'})\n",
    "            if div_baths == None:\n",
    "                building_baths = 'NA'\n",
    "            else:\n",
    "                building_baths = div_baths.text.strip()\n",
    "            if building_baths == 'â€”Baths':\n",
    "                building_baths = 'NA'\n",
    "            else:\n",
    "                building_baths = '\"' + building_baths + '\"'\n",
    "            description_p = soup4.find('p', {'class':re.compile('text-base')})\n",
    "            if description_p == None:\n",
    "                building_description = 'NA'\n",
    "            else:\n",
    "                building_description = description_p.text.strip()\n",
    "                building_description = '\"' + building_description + '\"'\n",
    "            span_location = soup4.find('span', {'class':re.compile('locality')})\n",
    "            if span_location == None:\n",
    "                building_location = 'NA'\n",
    "            else:\n",
    "                span_region = soup4.find('span', {'class':re.compile('region')})\n",
    "                building_location = span_location.text.strip()\n",
    "                building_region = span_region.text.strip()\n",
    "                building_location = '\"' + building_location + building_region + '\"'\n",
    "            div_type = soup4.findAll('div', {'class':re.compile('table-value')})\n",
    "            if len(div_type) == 0:\n",
    "                property_type = 'NA'\n",
    "                property_size = 'NA'\n",
    "                property_story = 'NA'\n",
    "            else:\n",
    "                property_type = div_type[5].text.strip()\n",
    "                if property_size == 'â€”':\n",
    "                    property_size = 'NA'\n",
    "                else:\n",
    "                    property_type = '\"' + property_type + '\"'\n",
    "                property_size = div_type[4].text.strip()\n",
    "                if property_size == 'â€”':\n",
    "                    property_size = 'NA'\n",
    "                else:\n",
    "                    property_size = '\"' + property_size + '\"'\n",
    "                property_story = div_type[5].text.strip()\n",
    "                if property_story == 'â€”':\n",
    "                    property_story = 'NA'\n",
    "                else:\n",
    "                    property_story = '\"' + property_story + '\"'\n",
    "            walking_div = soup4.find('div', {'class':re.compile('transport-icon-and-percentage walkscore')})\n",
    "            if walking_div == None:\n",
    "                walking_score = 'NA'\n",
    "            else:\n",
    "                walking_span = walking_div.find('span', {'class':re.compile('value')})\n",
    "                walking_score = walking_span.text.strip()\n",
    "                walking_score = '\"' + walking_score + '\"'\n",
    "            transit_div = soup4.find('div', {'class':re.compile('transport-icon-and-percentage transitscore')})\n",
    "            if transit_div == None:\n",
    "                transit_score = 'NA'\n",
    "            else:\n",
    "                transit_span = transit_div.find('span', {'class':re.compile('value')})\n",
    "                transit_score = transit_span.text.strip()\n",
    "                transit_score = '\"' + transit_score + '\"'\n",
    "            bike_div = soup4.find('div', {'class':re.compile('transport-icon-and-percentage bikescore')})\n",
    "            if bike_div == None:\n",
    "                bike_score = 'NA'\n",
    "            else:\n",
    "                bike_span = bike_div.find('span', {'class':re.compile('value')})\n",
    "                bike_score = bike_span.text.strip()\n",
    "                bike_score = '\"' + bike_score + '\"'\n",
    "                 \n",
    "            sold_list.append([\n",
    "                building_name, sold_price, building_beds, \n",
    "                building_baths, redfin_estimates, listed_price, building_location, \n",
    "                property_type, property_size, property_story, \n",
    "                walking_score, transit_score, bike_score, building_description, sold_building_link])\n",
    "#create dataframe for building_list of sold buildingâ€™s information\n",
    "df2 = pd.DataFrame(sold_list, columns = ['building_name', 'sold_price', 'building_beds', 'building_baths',\n",
    "                                         'redfin_estimates', 'listed_price','building_location', \n",
    "                'property_type', 'property_size', 'property_story', \n",
    "                                         'walking_score', 'transit_score', 'bike_score',\n",
    "                                         'building_description', 'building_website'])\n",
    "df2.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
